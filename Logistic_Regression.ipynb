{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂºïÂÖ•ÂáΩÂºèÂ∫´\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Download the Adult dataset. Clean up the dataset and create x_train, y_train, x_test, y_test for training feature, training value, test feature, test label. All of these variables should be numpy arrays. Provide summary statistics for your training and test datasets so that TA can verify the correctness of your procedure. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËÆÄÊ™î\n",
    "data = pd.read_csv('adult_data.csv')\n",
    "test = pd.read_csv('adult_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê∏ÖÈô§ÈÅ∫Â§±ÂÄº\n",
    "data = data[data['workclass']!=' ?']\n",
    "data = data[data['occupation']!=' ?']\n",
    "data = data[data['native-country']!=' ?']\n",
    "data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞áË≥áÊñôËôïÁêÜÊàêdummyÂΩ¢Âºè\n",
    "workclass_d = pd.get_dummies(data['workclass'],drop_first=True)\n",
    "education_d = pd.get_dummies(data['education'],drop_first=True)\n",
    "marital_status_d = pd.get_dummies(data['marital-status'],drop_first=True)\n",
    "occupation_d = pd.get_dummies(data['occupation'],drop_first=True)\n",
    "relationship_d = pd.get_dummies(data['relationship'],drop_first=True)\n",
    "race_d = pd.get_dummies(data['race'],drop_first=True)\n",
    "sex_d = pd.get_dummies(data['sex'],drop_first=True)\n",
    "native_country_d = pd.get_dummies(data['native-country'],drop_first=True)\n",
    "\n",
    "# Âà™Èô§ËàäÊúâÂÄº\n",
    "del data['workclass'],data['education'],data['marital-status'],data['occupation'],data['relationship'],data['race'],data['sex'],data['native-country']\n",
    "data = pd.concat([data,workclass_d,education_d,marital_status_d,occupation_d,relationship_d,race_d,sex_d,native_country_d],axis = 1)\n",
    "del data['index'],data[' Holand-Netherlands']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê∏ÖÈô§ÈÅ∫Â§±ÂÄº\n",
    "test = test[test['workclass']!=' ?']\n",
    "test = test[test['occupation']!=' ?']\n",
    "test = test[test['native-country']!=' ?']\n",
    "test.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞áË≥áÊñôËôïÁêÜÊàêdummyÂΩ¢Âºè\n",
    "workclass_t = pd.get_dummies(test['workclass'],drop_first=True)\n",
    "education_t = pd.get_dummies(test['education'],drop_first=True)\n",
    "marital_status_t = pd.get_dummies(test['marital-status'],drop_first=True)\n",
    "occupation_t = pd.get_dummies(test['occupation'],drop_first=True)\n",
    "relationship_t = pd.get_dummies(test['relationship'],drop_first=True)\n",
    "race_t = pd.get_dummies(test['race'],drop_first=True)\n",
    "sex_t = pd.get_dummies(test['sex'],drop_first=True)\n",
    "native_country_t = pd.get_dummies(test['native-country'],drop_first=True)\n",
    "\n",
    "# Âà™Èô§ËàäÊúâÂÄº\n",
    "del test['workclass'],test['education'],test['marital-status'],test['occupation'],test['relationship'],test['race'],test['sex'],test['native-country']\n",
    "test = pd.concat([test,workclass_t,education_t,marital_status_t,occupation_t,relationship_t,race_t,sex_t,native_country_t],axis = 1)\n",
    "del test['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê™¢Êü•unique value ÊòØÂê¶ >= 10ÔºåËã•ÁÑ°ÂâáÂà™Èô§Ê¨Ñ‰Ωç\n",
    "for i in list(data.columns)[6:]:\n",
    "    if data[i].value_counts().min() < 10:\n",
    "        del data[i],test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞áË®ìÁ∑¥Ë≥áÊñôÈõÜÁâπÂæµÂíåÊ®ôÁ±§ÂàÜÈõ¢\n",
    "y_train = np.array(data['label'])\n",
    "train_y = data['label']\n",
    "del data['label']\n",
    "x_train = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞áÊ∏¨Ë©¶Ë≥áÊñôÈõÜÁâπÂæµÂíåÊ®ôÁ±§ÂàÜÈõ¢\n",
    "y_test = np.array(test['label'])\n",
    "test_y = test['label']\n",
    "del test['label']\n",
    "x_test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Puerto-Rico</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>South</th>\n",
       "      <th>Taiwan</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30162.000000</td>\n",
       "      <td>3.016200e+04</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.437902</td>\n",
       "      <td>1.897938e+05</td>\n",
       "      <td>10.121312</td>\n",
       "      <td>1092.007858</td>\n",
       "      <td>88.372489</td>\n",
       "      <td>40.931238</td>\n",
       "      <td>0.068530</td>\n",
       "      <td>0.738877</td>\n",
       "      <td>0.035608</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.911876</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.134665</td>\n",
       "      <td>1.056530e+05</td>\n",
       "      <td>2.549995</td>\n",
       "      <td>7406.346497</td>\n",
       "      <td>404.298370</td>\n",
       "      <td>11.979984</td>\n",
       "      <td>0.252657</td>\n",
       "      <td>0.439254</td>\n",
       "      <td>0.185313</td>\n",
       "      <td>0.275664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>0.060007</td>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.283480</td>\n",
       "      <td>0.046016</td>\n",
       "      <td>0.023026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.176272e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.784250e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.376285e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  30162.000000  3.016200e+04   30162.000000  30162.000000  30162.000000   \n",
       "mean      38.437902  1.897938e+05      10.121312   1092.007858     88.372489   \n",
       "std       13.134665  1.056530e+05       2.549995   7406.346497    404.298370   \n",
       "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.176272e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.784250e+05      10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.376285e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week     Local-gov       Private   Self-emp-inc  \\\n",
       "count    30162.000000  30162.000000  30162.000000   30162.000000   \n",
       "mean        40.931238      0.068530      0.738877       0.035608   \n",
       "std         11.979984      0.252657      0.439254       0.185313   \n",
       "min          1.000000      0.000000      0.000000       0.000000   \n",
       "25%         40.000000      0.000000      0.000000       0.000000   \n",
       "50%         40.000000      0.000000      1.000000       0.000000   \n",
       "75%         45.000000      0.000000      1.000000       0.000000   \n",
       "max         99.000000      1.000000      1.000000       1.000000   \n",
       "\n",
       "        Self-emp-not-inc  ...      Portugal   Puerto-Rico      Scotland  \\\n",
       "count       30162.000000  ...  30162.000000  30162.000000  30162.000000   \n",
       "mean            0.082853  ...      0.001127      0.003614      0.000365   \n",
       "std             0.275664  ...      0.033556      0.060007      0.019094   \n",
       "min             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "75%             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "max             1.000000  ...      1.000000      1.000000      1.000000   \n",
       "\n",
       "              South        Taiwan      Thailand   Trinadad&Tobago  \\\n",
       "count  30162.000000  30162.000000  30162.000000      30162.000000   \n",
       "mean       0.002354      0.001392      0.000564          0.000597   \n",
       "std        0.048461      0.037291      0.023734          0.024422   \n",
       "min        0.000000      0.000000      0.000000          0.000000   \n",
       "25%        0.000000      0.000000      0.000000          0.000000   \n",
       "50%        0.000000      0.000000      0.000000          0.000000   \n",
       "75%        0.000000      0.000000      0.000000          0.000000   \n",
       "max        1.000000      1.000000      1.000000          1.000000   \n",
       "\n",
       "        United-States       Vietnam    Yugoslavia  \n",
       "count    30162.000000  30162.000000  30162.000000  \n",
       "mean         0.911876      0.002122      0.000530  \n",
       "std          0.283480      0.046016      0.023026  \n",
       "min          0.000000      0.000000      0.000000  \n",
       "25%          1.000000      0.000000      0.000000  \n",
       "50%          1.000000      0.000000      0.000000  \n",
       "75%          1.000000      0.000000      0.000000  \n",
       "max          1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ë®ìÁ∑¥ÈõÜxÁöÑÊïòËø∞Áµ±Ë®à\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Puerto-Rico</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>South</th>\n",
       "      <th>Taiwan</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>1.506000e+04</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.768327</td>\n",
       "      <td>1.896164e+05</td>\n",
       "      <td>10.112749</td>\n",
       "      <td>1120.301594</td>\n",
       "      <td>89.041899</td>\n",
       "      <td>40.951594</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.731806</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>0.086122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.380676</td>\n",
       "      <td>1.056150e+05</td>\n",
       "      <td>2.558727</td>\n",
       "      <td>7703.181842</td>\n",
       "      <td>406.283245</td>\n",
       "      <td>12.062831</td>\n",
       "      <td>0.252768</td>\n",
       "      <td>0.443034</td>\n",
       "      <td>0.191158</td>\n",
       "      <td>0.280554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>0.028218</td>\n",
       "      <td>0.023043</td>\n",
       "      <td>0.278089</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.021555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.166550e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.779550e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.385888e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  15060.000000  1.506000e+04   15060.000000  15060.000000  15060.000000   \n",
       "mean      38.768327  1.896164e+05      10.112749   1120.301594     89.041899   \n",
       "std       13.380676  1.056150e+05       2.558727   7703.181842    406.283245   \n",
       "min       17.000000  1.349200e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.166550e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.779550e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.385888e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   3770.000000   \n",
       "\n",
       "       hours-per-week     Local-gov       Private   Self-emp-inc  \\\n",
       "count    15060.000000  15060.000000  15060.000000   15060.000000   \n",
       "mean        40.951594      0.068592      0.731806       0.037981   \n",
       "std         12.062831      0.252768      0.443034       0.191158   \n",
       "min          1.000000      0.000000      0.000000       0.000000   \n",
       "25%         40.000000      0.000000      0.000000       0.000000   \n",
       "50%         40.000000      0.000000      1.000000       0.000000   \n",
       "75%         45.000000      0.000000      1.000000       0.000000   \n",
       "max         99.000000      1.000000      1.000000       1.000000   \n",
       "\n",
       "        Self-emp-not-inc  ...      Portugal   Puerto-Rico      Scotland  \\\n",
       "count       15060.000000  ...  15060.000000  15060.000000  15060.000000   \n",
       "mean            0.086122  ...      0.001859      0.004382      0.000598   \n",
       "std             0.280554  ...      0.043080      0.066057      0.024440   \n",
       "min             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "75%             0.000000  ...      0.000000      0.000000      0.000000   \n",
       "max             1.000000  ...      1.000000      1.000000      1.000000   \n",
       "\n",
       "              South        Taiwan      Thailand   Trinadad&Tobago  \\\n",
       "count  15060.000000  15060.000000  15060.000000      15060.000000   \n",
       "mean       0.001992      0.000863      0.000797          0.000531   \n",
       "std        0.044589      0.029369      0.028218          0.023043   \n",
       "min        0.000000      0.000000      0.000000          0.000000   \n",
       "25%        0.000000      0.000000      0.000000          0.000000   \n",
       "50%        0.000000      0.000000      0.000000          0.000000   \n",
       "75%        0.000000      0.000000      0.000000          0.000000   \n",
       "max        1.000000      1.000000      1.000000          1.000000   \n",
       "\n",
       "        United-States       Vietnam    Yugoslavia  \n",
       "count    15060.000000  15060.000000  15060.000000  \n",
       "mean         0.915538      0.001262      0.000465  \n",
       "std          0.278089      0.035498      0.021555  \n",
       "min          0.000000      0.000000      0.000000  \n",
       "25%          1.000000      0.000000      0.000000  \n",
       "50%          1.000000      0.000000      0.000000  \n",
       "75%          1.000000      0.000000      0.000000  \n",
       "max          1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ê∏¨Ë©¶ÈõÜxÁöÑÊïòËø∞Áµ±Ë®à\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    30162.000000\n",
       " mean         0.248922\n",
       " std          0.432396\n",
       " min          0.000000\n",
       " 25%          0.000000\n",
       " 50%          0.000000\n",
       " 75%          0.000000\n",
       " max          1.000000\n",
       " Name: label, dtype: float64,\n",
       " count    15060.000000\n",
       " mean         0.245684\n",
       " std          0.430506\n",
       " min          0.000000\n",
       " 25%          0.000000\n",
       " 50%          0.000000\n",
       " 75%          0.000000\n",
       " max          1.000000\n",
       " Name: label, dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yÁöÑÊïòËø∞Áµ±Ë®à\n",
    "train_y.describe(),test_y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 Derive the gradient and hessian matrix for the new E(w). ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê≤íÊúâÊà™Ë∑ùÈ†Ö\n",
    "vec = np.ones((np.shape(x_train[0])))\n",
    "lambda_vec = np.diag(vec) \n",
    "reg_vec = lambda_vec\n",
    "# kick start weight\n",
    "weights = np.dot(np.dot(np.linalg.inv(np.dot(x_train.T,x_train)+np.eye(x_train.shape[1])),x_train.T),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âª∫ÊßãsigmoidÂáΩÊï∏\n",
    "def sigmoid(a):\n",
    "    return 1/(1+np.exp(-a))\n",
    "\n",
    "# Âª∫ÊßãgradientÂáΩÊï∏\n",
    "def gradient(x,y,w,reg_vec):                                  \n",
    "    sig = sigmoid(np.dot(x,w))                              \n",
    "    grad = reg_vec.dot(w)+np.dot(x.T,(sig - y)) #ÊØîÂéüÊú¨ÁöÑerror function Â§öÂá∫lambda_vecÂÖßÁ©çweightÈ†Ö\n",
    "    return grad\n",
    "\n",
    "# Âª∫ÊßãhessianÂáΩÊï∏\n",
    "def hessian(x,w,reg_vec):                                   \n",
    "    sig = sigmoid(np.dot(x,w))   \n",
    "    R = np.diag((1-sig)*sig)\n",
    "    result = reg_vec+np.dot(np.dot(x.T,R),x) #ÊØîÂéüÊú¨ÁöÑerror function Â§öÂá∫lambda_vecÈ†Ö\n",
    "    return result\n",
    "\n",
    "# Êõ¥Êñ∞coef\n",
    "def updatew(x,y,w,reg_vec):\n",
    "    hessianInv = np.linalg.inv(hessian(x,w,reg_vec))                         \n",
    "    grad = gradient(x,y,w,reg_vec)                                  \n",
    "    w = w - np.dot(hessianInv, grad)                     \n",
    "    return w\n",
    "\n",
    "# Âª∫Êßãcost functionÂáΩÊï∏\n",
    "def cost(x,y,w,reg_vec):\n",
    "    pro = sigmoid(np.dot(x,w))\n",
    "    result = 1/2*np.dot(np.dot(w.T,reg_vec),w)+sum(y * np.log(pro) + (1-y) * np.log(1-pro))\n",
    "    result = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.29994020e+05,  1.79383619e+09,  8.66827172e+04, -6.47340778e+06,\n",
       "        2.27665361e+05,  3.57652892e+05,  5.73229125e+02,  7.45786561e+03,\n",
       "        8.01870311e+01,  7.09496370e+02,  3.79226342e+02,  6.83783122e+00,\n",
       "        4.79554694e+02,  1.66688383e+02,  7.09424563e+01,  1.34930702e+02,\n",
       "        2.52117093e+02,  2.08647842e+02,  3.11034018e+02,  3.94264451e+02,\n",
       "        9.13318412e+02, -2.60977152e+01,  3.70187250e+03,  1.16667923e+02,\n",
       "        2.24681517e+01, -3.96443404e+01,  2.33157210e+03,  3.08489032e+00,\n",
       "        2.18925567e+03,  1.61658050e+02,  4.50908086e+03,  4.19801282e+02,\n",
       "        3.53339218e+02,  1.33128734e+03,  5.27284295e+02,  4.07854170e+02,\n",
       "        6.12444898e+02,  7.98583599e+02,  1.50637141e+03,  7.07475737e+01,\n",
       "        6.44614578e+02,  1.63657387e+02,  1.05899328e+03,  2.46243692e+02,\n",
       "        5.45862198e+02,  3.24324859e+03,  4.18042434e+02,  2.18465636e+03,\n",
       "        1.44557770e+03,  1.77795939e+02,  2.59809223e+02,  1.13231915e+03,\n",
       "        9.95511628e+01,  7.79372995e+03,  5.35163228e+03,  2.62123444e+01,\n",
       "        1.87516058e+01,  2.63565728e+01,  2.70634316e+01,  3.19024660e+01,\n",
       "        1.04194957e+01,  4.31325628e+01,  2.02817218e+01,  4.41165891e+00,\n",
       "        3.06853300e+01,  8.31986453e+00,  2.92058100e+01,  1.79157665e+01,\n",
       "        5.17713733e+00,  4.88553194e+00,  4.17251866e+00,  1.95044870e+01,\n",
       "        7.31553945e+00,  8.21938989e+00,  1.58780532e+01,  3.23984671e+01,\n",
       "        1.20140908e+01,  6.88095399e+00,  2.80021680e+02,  1.48959304e+01,\n",
       "        6.84437138e+00,  1.33941175e+01,  4.85687749e+01,  1.96305871e+01,\n",
       "        1.39123081e+01,  4.53756280e+01,  3.88959126e+00,  2.47729461e+01,\n",
       "        6.45787080e+00,  6.13130721e+00,  7.40643754e+00,  8.46181242e+03,\n",
       "        2.81101369e+01,  3.46098471e+00])"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# derive gradient matrix\n",
    "gradient(x_train,y_train,weights,reg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.19628264e+07, 5.23156647e+10, 2.82292084e+06, ...,\n",
       "        2.55355039e+05, 5.25081454e+02, 1.48049723e+02],\n",
       "       [5.23156647e+10, 3.45170247e+14, 1.38764747e+10, ...,\n",
       "        1.24641157e+09, 2.60837602e+06, 8.20889968e+05],\n",
       "       [2.82292084e+06, 1.38764747e+10, 7.87161353e+05, ...,\n",
       "        6.77477153e+04, 1.49774959e+02, 3.77271733e+01],\n",
       "       ...,\n",
       "       [2.55355039e+05, 1.24641157e+09, 6.77477153e+04, ...,\n",
       "        6.66437908e+03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.25081454e+02, 2.60837602e+06, 1.49774959e+02, ...,\n",
       "        0.00000000e+00, 1.67840104e+01, 0.00000000e+00],\n",
       "       [1.48049723e+02, 8.20889968e+05, 3.77271733e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.82051722e+00]])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# derive hessian matrix\n",
    "hessian(x_train,weights,reg_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3 Create your mylogistic_l2 class. Show the learned  ùë§ as well as test accuracy for the cases below. If ùë§ is too long for you, show selected  ùë§ for continuous-valued, binary-valued, and the constant term.\n",
    "\n",
    "#### Case 1: lambda = 1 for all coefficients\n",
    "#### Case 2: lambda = 1 for all but the intercept, no regularization for intercept term.\n",
    "#### Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âª∫Êßã mylogistic class\n",
    "class mylogistic_l2():\n",
    "    \n",
    "    def __init__(self,reg_vec,max_iter,tol,add_intercept):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        \n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        # Ê∑ªÂä†Êà™Ë∑ùÈ†Ö\n",
    "        if self.add_intercept  :\n",
    "            intercept = np.ones((self.x.shape[0],1))\n",
    "            self.x = np.hstack((intercept,self.x))  \n",
    "\n",
    "        return self\n",
    "    \n",
    "    # ÁîüÊàêÈ†êÊ∏¨ÂáΩÊï∏\n",
    "    def predict(self,test):\n",
    "        self.test = test\n",
    "        if self.add_intercept:\n",
    "            intercept_t = np.ones((test.shape[0],1))\n",
    "            test = np.hstack((intercept_t,test))  \n",
    "            \n",
    "        b = np.diag(self.reg_vec).mean() \n",
    "        # closed-form solution of ridge regression\n",
    "        weights = np.dot(np.dot(np.linalg.inv(np.dot(self.x.T,self.x)+ b*(np.eye(self.x.shape[1]))),self.x.T),self.y) \n",
    "        \n",
    "        #Ë®ìÁ∑¥Ê®°Âûã\n",
    "        for i in range(self.max_iter):\n",
    "            cost0 = cost(self.x,self.y,weights,self.reg_vec) # ÂàùÂßã error            \n",
    "            weights = updatew(self.x,self.y,weights,self.reg_vec)\n",
    "            cost1 = cost(self.x,self.y,weights,self.reg_vec) # Ë®ìÁ∑¥Âæå error\n",
    "            if cost1 - cost0 < self.tol: #Â¶ÇÊûúerror‰∏ãÈôçÁ®ãÂ∫¶Â∞èÊñºtolerance,ÁµêÊùüËø¥Âúà\n",
    "                self.w = weights\n",
    "\n",
    "                break   \n",
    "        \n",
    "        # Ëº∏Âá∫È†êÊ∏¨ÂÄº    \n",
    "        ypred = np.zeros((test.shape[0]))\n",
    "        A = sigmoid(np.dot(test,weights.T))\n",
    "        \n",
    "        for i in range(len(ypred)):\n",
    "            if A[i]<0.5:\n",
    "                ypred[i]=0\n",
    "            else:\n",
    "                ypred[i]=1\n",
    "        return ypred\n",
    "     \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.ones((np.shape(x_train[0])[0]+1,))\n",
    "lambda_vec = np.diag(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained weights: [-6.98439490e+00  2.40874163e-02  7.10581228e-07  1.59429551e-01\n",
      "  3.16153053e-04  6.37558167e-04  2.85041062e-02 -7.04529809e-01\n",
      " -5.18910693e-01 -3.29118884e-01 -9.95452327e-01 -8.26441356e-01\n",
      " -1.26643790e+00 -2.60450215e-01 -7.10065894e-02  4.84787188e-02\n",
      " -1.00790263e-01 -4.21534800e-01 -2.65656889e-01  1.02981921e-01\n",
      "  2.59904338e-01  5.71342126e-01  1.09619630e+00  9.01947263e-02\n",
      "  7.66082249e-01 -1.28388908e+00  1.16716377e+00  2.62286832e-01\n",
      "  1.65378838e+00  1.41618328e+00 -3.45365286e-02 -5.40243997e-01\n",
      " -1.28374760e-01  1.41256456e-01  4.63182428e-02  7.89557407e-01\n",
      " -9.87642780e-01 -7.07240411e-01 -2.85830133e-01 -8.35219451e-01\n",
      " -1.60726777e+00  5.06399304e-01  5.74582793e-01  2.82067725e-01\n",
      "  6.39121903e-01 -1.11255640e-01 -2.14544924e-01 -7.91361735e-01\n",
      " -1.29999876e+00 -3.62180865e-01  1.27476265e+00  4.26461335e-01\n",
      "  7.93672953e-02 -2.39243132e-01  2.38015477e-01  8.18762775e-01\n",
      "  2.30936488e-01 -7.02985700e-01 -1.43181823e+00  2.56052220e-01\n",
      " -1.05914825e+00 -2.16919570e-01 -5.62700863e-01  2.01883086e-01\n",
      "  3.95420550e-01  3.38143120e-01 -8.10747901e-01 -2.44137410e-01\n",
      " -8.00738517e-02 -2.01908221e-01 -1.82836073e-01 -1.24361205e-01\n",
      " -5.05012534e-01 -6.15586420e-02  3.21413477e-01  6.53229152e-01\n",
      " -6.34699211e-02  1.30312310e-01 -4.68774773e-01 -6.11347315e-01\n",
      " -5.30914992e-01 -7.66499215e-01 -5.70346197e-01  2.21562730e-01\n",
      " -7.60760781e-02 -6.79647201e-02 -3.40906731e-01 -1.96912659e-01\n",
      " -1.13886850e+00 -2.37548279e-01 -4.45191734e-01 -2.97352777e-01\n",
      "  9.28764033e-02 -9.83822321e-01  3.99382396e-01]\n"
     ]
    }
   ],
   "source": [
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ë®àÁÆóÊ∫ñÁ¢∫Áéá\n",
    "def precision(ypred,y_test):\n",
    "    count = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if ypred[i]==y_test[i]:\n",
    "            count += 1\n",
    "    return(count/len(y_test))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84867197875166"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Case1 È†êÊ∏¨Ê∫ñÂ∫¶ \n",
    "precision(ypred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.ones((x_train.shape[1],))\n",
    "vec = list(vec)\n",
    "vec.insert(0,0)\n",
    "vec = np.array(vec)\n",
    "lambda_vec = np.diag(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained weights: [-9.08516189e+00  2.54046944e-02  7.55272795e-07  2.86221788e-01\n",
      "  3.16851513e-04  6.39642191e-04  2.94489004e-02 -6.57915393e-01\n",
      " -4.68145369e-01 -2.90957839e-01 -9.55543513e-01 -7.78419402e-01\n",
      " -1.25488844e+00 -1.73277579e-01 -1.03503848e-01  6.29950500e-01\n",
      "  4.37694193e-01  2.45531123e-02  5.43174182e-02 -4.23991307e-01\n",
      " -1.45402854e-01 -8.72441846e-02  7.92967941e-02 -6.85663272e-02\n",
      " -1.74148306e-02 -1.13549821e+00  2.70042657e-01 -1.78346516e-02\n",
      "  1.98162707e+00  1.82611848e+00 -2.66120911e-03 -5.00992102e-01\n",
      " -1.02305805e-01  1.64068426e-01  7.06330492e-02  8.05750008e-01\n",
      " -9.74784281e-01 -6.77440033e-01 -2.56717024e-01 -8.08661088e-01\n",
      " -1.63961846e+00  5.20589652e-01  5.92800157e-01  2.96953568e-01\n",
      "  6.61463239e-01 -8.58650456e-02  1.83604291e-01 -5.64658888e-01\n",
      " -9.46700288e-01  5.84992476e-02  1.32772822e+00  7.37234582e-01\n",
      "  3.50705212e-01  1.99620737e-02  5.03478338e-01  8.52218449e-01\n",
      "  4.41072563e-01 -5.45679152e-01 -1.28100272e+00  4.67062387e-01\n",
      " -9.07337376e-01 -6.63096415e-02 -3.67205079e-01  4.12843333e-01\n",
      "  5.76734969e-01  5.61452112e-01 -6.39935820e-01 -7.24811238e-02\n",
      "  7.77366188e-02 -1.55713881e-01 -4.58440172e-02  1.97462607e-02\n",
      " -3.33826765e-01  1.35213228e-01  4.78260899e-01  8.70343690e-01\n",
      "  1.31600629e-01  3.05085559e-01 -3.44952489e-01 -3.74882104e-01\n",
      " -3.74429036e-01 -6.76284494e-01 -4.23182843e-01  3.97536931e-01\n",
      "  1.19267452e-01  1.24711102e-01 -1.25979216e-01 -6.90670327e-02\n",
      " -9.84456401e-01 -7.72738436e-02 -3.31384592e-01 -1.68950580e-01\n",
      "  3.30509951e-01 -8.31076475e-01  5.65267244e-01]\n"
     ]
    }
   ],
   "source": [
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848140770252324"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Case2 È†êÊ∏¨Ê∫ñÂ∫¶ \n",
    "precision(ypred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.ones((x_train.shape[1],))\n",
    "vec = list(vec)\n",
    "vec.insert(0,0)\n",
    "binary = []\n",
    "for i in range(len(vec[7:])):\n",
    "    binary.append(0.5)     \n",
    "vec = vec[:7]    \n",
    "for i in binary:\n",
    "    vec.append(i)\n",
    "vec = np.array(vec)\n",
    "lambda_vec = np.diag(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained weights: [-9.24240384e+00  2.54569996e-02  7.55782487e-07  2.96967946e-01\n",
      "  3.17158832e-04  6.40156865e-04  2.94787400e-02 -6.74055740e-01\n",
      " -4.82744893e-01 -3.06741908e-01 -9.71485389e-01 -7.95922599e-01\n",
      " -1.71627397e+00 -1.77452378e-01 -1.18934036e-01  7.37963157e-01\n",
      "  4.98074247e-01  5.41845226e-02  7.59969156e-02 -4.85880363e-01\n",
      " -1.93107062e-01 -1.56904263e-01 -1.80127503e-02 -9.41033291e-02\n",
      " -9.65277139e-02 -2.08212143e+00  1.84596079e-01 -5.46169189e-02\n",
      "  2.29443408e+00  1.92209768e+00  3.97914923e-03 -4.93871332e-01\n",
      " -9.68541694e-02  1.72205406e-01  7.00268156e-02  8.06849109e-01\n",
      " -9.81753793e-01 -6.83623829e-01 -2.57096675e-01 -8.14551920e-01\n",
      " -2.15016199e+00  5.20827572e-01  5.96488880e-01  2.97862010e-01\n",
      "  6.64171093e-01 -8.63816700e-02  2.75307081e-01 -5.23123755e-01\n",
      " -8.76894327e-01  1.53958827e-01  1.33705597e+00  8.06325043e-01\n",
      "  3.87982441e-01  6.60232637e-02  5.39885242e-01  8.57322892e-01\n",
      "  4.18203102e-01 -6.47329039e-01 -1.56510664e+00  4.49851596e-01\n",
      " -1.16304774e+00 -1.15650185e-01 -4.41434093e-01  3.92887173e-01\n",
      "  6.07829833e-01  5.40258705e-01 -7.58941840e-01 -1.18622393e-01\n",
      "  5.98073651e-02 -2.76518985e-01 -1.12408358e-01 -6.07213203e-03\n",
      " -4.14950941e-01  1.05780555e-01  5.24958660e-01  8.72338231e-01\n",
      "  1.06990962e-01  2.68635266e-01 -4.88231510e-01 -4.29039756e-01\n",
      " -4.87710084e-01 -1.02840498e+00 -5.54811200e-01  3.38381590e-01\n",
      "  9.10049986e-02  1.07499155e-01 -1.75653805e-01 -1.17890664e-01\n",
      " -1.12845882e+00 -1.49116540e-01 -4.61000115e-01 -2.50504738e-01\n",
      "  2.90270803e-01 -1.00466288e+00  6.39514382e-01]\n"
     ]
    }
   ],
   "source": [
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred = logic1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847808764940239"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Case3 È†êÊ∏¨Ê∫ñÂ∫¶ \n",
    "precision(ypred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.4 Further split the training data into subtraining (90%) and tuning (10%) to search for the best hyperparameters. Set the regularization coefficient for the constant term to zero. Allow different regularizations for continuous-valued and binary-valued features. Let ùëé1 and ùëé2 denote the regularization coefficients for continuous-valued and binary-valued features. Search the best ùëé1 and ùëé2 and report the test accuracy using the best hyper-parameters. You should follow the following procedure to search for the best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞áË≥áÊñôÂàáÂàÜÊàê subtrain,tune\n",
    "from sklearn import model_selection\n",
    "x_subtrain, x_tuning, y_subtrain, y_tuning = model_selection.train_test_split(x_train,y_train, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.Choose a set of grids among a reasonable range. For example, 10 grids in [0.01, 100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÊêúÁ¥¢lambda_vec,Êà™Ë∑ùÈ†Ö coef Ë®≠ÁÇ∫0\n",
    "def lambda_vector(a1,a2):\n",
    "    vec = np.diag([0]+[a1]*6+[a2]*88)\n",
    "    return vec\n",
    "# set up reasonable grid range\n",
    "grid = np.logspace(-2,2,base = 5,num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04      ,  0.08179247,  0.16725021,  0.34199519,  0.69931579,\n",
       "        1.42996915,  2.92401774,  5.97906587, 12.22606424, 25.        ])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Conduct grid search with the constraint that  ùëé1=ùëé2.Record the best value ùëé‚àó1 and ùëé‚àó2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best a1 & a2: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "accuracy = []\n",
    "for i in grid:\n",
    "    logit_tune = mylogistic_l2(reg_vec = lambda_vector(i,i), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logit_tune.fit(x_subtrain,y_subtrain)\n",
    "    ypred = logit_tune.predict(x_tuning)\n",
    "    accuracy.append(precision(ypred,y_tuning))\n",
    "print('Best a1 & a2:',grid[accuracy.index(max(accuracy))])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Fix ùëé1 = ùëé‚àó1, and search ùëé2 for the best value, call the result the new  ùëé‚àó2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best a2: 0.04\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for i in grid:\n",
    "    logit_tune = mylogistic_l2(reg_vec = lambda_vector(0.04,i), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logit_tune.fit(x_subtrain,y_subtrain)\n",
    "    ypred = logit_tune.predict(x_tuning)\n",
    "    accuracy.append(precision(ypred,y_tuning))\n",
    "print('New Best a2:',grid[accuracy.index(max(accuracy))])  \n",
    "# ÈÄôÈÇäÁôºÁèæÊúÄ‰Ω≥Ë°®ÁèæÁöÑ a1,a2ÈÉΩÊòØ 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Fix ùëé2=ùëé‚àó2, and search ùëé1 for the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best a1: 0.04\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for i in grid:\n",
    "    logit_tune = mylogistic_l2(reg_vec = lambda_vector(i,0.04), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logit_tune.fit(x_subtrain,y_subtrain)\n",
    "    ypred = logit_tune.predict(x_tuning)\n",
    "    accuracy.append(precision(ypred,y_tuning))\n",
    "print('New Best a1:',grid[accuracy.index(max(accuracy))])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Report the selected  ùëé1 and ùëé2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best a1 & a2: (0.04,0.04)\n"
     ]
    }
   ],
   "source": [
    "print('best a1 & a2: (0.04,0.04)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Train a model using the selected hyper-parameters, and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505137553861452"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_tune = mylogistic_l2(reg_vec = lambda_vector(0.04,0.04), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logit_tune.fit(x_subtrain,y_subtrain)\n",
    "ypred = logit_tune.predict(x_tuning)\n",
    "precision(ypred,y_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.5 Use sklearn.linear_model.LogisticRegression to train and test the model (including hyperparameter tuning). Compare the estimated parameters and test accuracy with those from your own models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÊúÄ‰Ω≥ÂèÉÊï∏: {'C': 1.429969148308729, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# sklearnÁöÑÁî®GridSearch TuneÂÆåÂèÉÊï∏Âæå‰ª•IRLSÈ†êÊ∏¨Ë≥áÊñô\n",
    "logit = linear_model.LogisticRegression(max_iter = 1000,tol = 1e-5,solver = 'newton-cg')\n",
    "\n",
    "# Âª∫Á´ãGridËÆìsklearnÊêúÁ¥¢\n",
    "grid={\"C\":np.logspace(-2,2,base = 5,num=10),\"penalty\":[\"l2\"]}\n",
    "\n",
    "# Ë™øÂèÉ\n",
    "logit_cv=GridSearchCV(logit,grid)\n",
    "logit_cv.fit(x_subtrain,y_subtrain)\n",
    "print(\"ÊúÄ‰Ω≥ÂèÉÊï∏:\",logit_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.429969148308729, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=1e-05, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Áî®Ë™øÊï¥ÂæåÂèÉÊï∏È†êÊ∏¨Ë≥áÊñô\n",
    "logit_tuned = linear_model.LogisticRegression(C=logit_cv.best_params_['C'], penalty='l2',solver = 'newton-cg',tol=1e-5)\n",
    "logit_tuned.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn È†êÊ∏¨Ê∫ñÁ¢∫Áéá: 0.848937583001328\n",
      "sklearn weights: [-4.3562771] [[ 2.20576945e-02  6.59589456e-07  1.33031575e-01  3.15741126e-04\n",
      "   6.33754805e-04  2.73527593e-02 -7.93628112e-01 -6.18816166e-01\n",
      "  -4.03175934e-01 -1.07397976e+00 -9.31938685e-01 -1.53358103e-01\n",
      "  -7.36493248e-01 -4.53894816e-01 -2.79906573e-01 -5.09367079e-01\n",
      "  -9.33883716e-01 -7.03434884e-01 -2.06905709e-01 -6.88335367e-02\n",
      "   3.08469487e-01  8.94418890e-01 -2.78387874e-01  5.24822127e-01\n",
      "  -1.87457555e-01  9.49955741e-01 -8.78893636e-02  2.59427751e-01\n",
      "   6.60478285e-01 -2.10752599e-01 -6.56219948e-01 -2.68919567e-01\n",
      "  -9.27361937e-03 -5.69537487e-02  7.03256979e-01 -1.08673180e+00\n",
      "  -8.51024872e-01 -4.09176405e-01 -9.47931406e-01 -3.48162159e-01\n",
      "   4.22850983e-01  4.82611575e-01  1.94869924e-01  5.39600206e-01\n",
      "  -2.27413403e-01 -9.21882527e-01 -1.13314426e+00 -1.91022555e+00\n",
      "  -1.12555731e+00  1.14440281e+00 -6.14626824e-01 -6.98125566e-01\n",
      "  -7.52625812e-01 -5.01095815e-01  7.50854488e-01  2.56215591e-02\n",
      "  -2.83929645e-01 -3.60722889e-01  1.11546701e-02 -2.94053712e-01\n",
      "  -9.32167357e-02 -2.64240815e-01  1.16044117e-02  6.37383782e-02\n",
      "   6.83832605e-02 -2.27540257e-01 -1.20780405e-01 -6.53039878e-02\n",
      "  -2.27141039e-02 -3.41973902e-02 -4.03887714e-02 -2.81403058e-01\n",
      "  -7.83840669e-02  2.51392423e-02  1.76560544e-01 -1.05488911e-01\n",
      "   2.16839462e-02 -7.11359374e-02 -8.48802900e-01 -1.38947314e-01\n",
      "  -9.46598754e-02 -1.14699652e-01  1.67800496e-01 -1.07458660e-01\n",
      "  -9.57267540e-02 -3.00107579e-01 -3.47114166e-02 -3.84776209e-01\n",
      "  -6.39260687e-02 -5.92314002e-02 -6.38117673e-02 -4.23705009e-02\n",
      "  -2.80979864e-01  3.59338655e-02]]\n",
      "\n",
      "mylogit È†êÊ∏¨Ê∫ñÁ¢∫Áéá: 0.8505137553861452\n",
      "mylogit weights: [-8.67934378e+00  2.58763643e-02  8.58883507e-07  3.34760454e-01\n",
      "  3.16849952e-04  6.35917903e-04  2.92943240e-02 -7.81822330e-01\n",
      " -5.45718412e-01 -3.47564361e-01 -1.03188904e+00 -8.66595453e-01\n",
      " -3.45697904e+00 -2.20681189e-01 -1.69278357e-01  1.32595851e-01\n",
      "  5.07898722e-01  1.26960470e-01  8.07224657e-02 -7.63738188e-01\n",
      " -4.08567518e-01 -4.53255246e-01 -4.74424037e-01 -2.73487051e-01\n",
      " -4.48369584e-01 -5.00273208e+00 -1.99089218e-01 -2.47356114e-01\n",
      "  2.63485458e+00  2.08346500e+00  4.23855466e-02 -4.88240779e-01\n",
      " -7.43276685e-02  1.14714088e-01  9.48805242e-02  8.52096088e-01\n",
      " -9.07530597e-01 -6.75086919e-01 -2.50714127e-01 -7.84394485e-01\n",
      " -2.99505574e+00  5.55971076e-01  6.90636626e-01  3.21332897e-01\n",
      "  6.82264036e-01 -4.18476483e-02  4.21654240e-01 -4.45057654e-01\n",
      " -7.37006723e-01  3.03817154e-01  1.36358023e+00  7.68136881e-01\n",
      "  4.01481150e-01  2.24115810e-01  5.54377552e-01  8.43920609e-01\n",
      " -5.97153077e-01 -1.64292305e+00 -3.45074804e+00 -4.80823905e-01\n",
      " -4.28481618e+00 -1.08803510e+00 -1.54664190e+00 -3.86615598e-01\n",
      "  5.15442405e-02 -2.46775504e-01 -1.61217808e+00 -1.64692877e+00\n",
      " -1.19951340e+00 -1.55057601e+00 -9.40051984e-01 -7.51398708e-01\n",
      " -1.18915041e+00 -3.24562649e-01 -2.51150544e-01  1.69749676e-01\n",
      " -7.69564641e-01 -5.00242333e-01 -1.12156147e+00 -1.29549057e+00\n",
      " -1.30923430e+00 -2.58717060e+00 -1.45096023e+00 -6.14268759e-01\n",
      " -1.00948568e+00 -6.85777905e-01 -1.19507957e+00 -1.60489816e+00\n",
      " -1.64327486e+00 -8.52218981e-01 -1.44531600e+00 -1.18796315e+00\n",
      " -6.03176231e-01 -1.90257876e+00 -1.35393575e-01]\n"
     ]
    }
   ],
   "source": [
    "print('sklearn È†êÊ∏¨Ê∫ñÁ¢∫Áéá:',logit_tuned.score(x_test,y_test))\n",
    "print('sklearn weights:',logit_tuned.intercept_,logit_tuned.coef_)\n",
    "print()\n",
    "print('mylogit È†êÊ∏¨Ê∫ñÁ¢∫Áéá:',precision(ypred,y_tuning))\n",
    "print('mylogit weights:',logit_tune.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÁµêË™ûÔºö ‰ª•sklearnÈ†êÊ∏¨Âá∫ÁöÑË≥áÊñôÊ∫ñÂ∫¶ËàáËá™ÂÆöÁæ©Ê®°ÂûãÁõ∏ÊØîËºÉÁï•ÁÇ∫‰ΩéÔºåËÄåÂú®TuneÂèÉÊï∏ÊôÇÊâÄËä±Ë≤ªÁöÑÊôÇÈñìÂ∑Æ‰∏çÂ§öÔºåÈÉΩÈùûÂ∏∏ËÄóÊôÇ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
